{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a139012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Feb 13 09:33:46 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   36C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d216999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting vector_addition.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile vector_addition.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cuda.h>\n",
    "#include <time.h>\n",
    "\n",
    "__global__ void vectorAddGPU(int *A, int *B, int *C, int n)\n",
    "{\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n)\n",
    "        C[idx] = A[idx] + B[idx];\n",
    "}\n",
    "\n",
    "void vectorAddCPU(int *A, int *B, int *C, int n)\n",
    "{\n",
    "    for (int i = 0; i < n; i++)\n",
    "        C[i] = A[i] + B[i];\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[])\n",
    "{\n",
    "    if (argc != 2)\n",
    "    {\n",
    "        printf(\"Usage: ./vector_addition <vector_size>\\n\");\n",
    "        return 0;\n",
    "    }\n",
    "\n",
    "    int n = atoi(argv[1]);\n",
    "    int size = n * sizeof(int);\n",
    "\n",
    "    int *A = (int *)malloc(size);\n",
    "    int *B = (int *)malloc(size);\n",
    "    int *C_cpu = (int *)malloc(size);\n",
    "    int *C_gpu = (int *)malloc(size);\n",
    "\n",
    "    for (int i = 0; i < n; i++)\n",
    "    {\n",
    "        A[i] = rand() % 100;\n",
    "        B[i] = rand() % 100;\n",
    "    }\n",
    "\n",
    "    clock_t start_cpu = clock();\n",
    "    vectorAddCPU(A, B, C_cpu, n);\n",
    "    clock_t end_cpu = clock();\n",
    "\n",
    "    int *d_A, *d_B, *d_C;\n",
    "    cudaMalloc((void **)&d_A, size);\n",
    "    cudaMalloc((void **)&d_B, size);\n",
    "    cudaMalloc((void **)&d_C, size);\n",
    "\n",
    "    cudaMemcpy(d_A, A, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_B, B, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    cudaEvent_t start_gpu, stop_gpu;\n",
    "    cudaEventCreate(&start_gpu);\n",
    "    cudaEventCreate(&stop_gpu);\n",
    "\n",
    "    int threads = 256;\n",
    "    int blocks = (n + threads - 1) / threads;\n",
    "\n",
    "    cudaEventRecord(start_gpu);\n",
    "    vectorAddGPU<<<blocks, threads>>>(d_A, d_B, d_C, n);\n",
    "    cudaEventRecord(stop_gpu);\n",
    "    cudaEventSynchronize(stop_gpu);\n",
    "\n",
    "    float gpu_time;\n",
    "    cudaEventElapsedTime(&gpu_time, start_gpu, stop_gpu);\n",
    "\n",
    "    printf(\"Vector Size: %d\\n\", n);\n",
    "    printf(\"CPU Time: %f ms\\n\",\n",
    "           (double)(end_cpu - start_cpu) * 1000 / CLOCKS_PER_SEC);\n",
    "    printf(\"GPU Time: %f ms\\n\", gpu_time);\n",
    "\n",
    "    cudaFree(d_A);\n",
    "    cudaFree(d_B);\n",
    "    cudaFree(d_C);\n",
    "    free(A);\n",
    "    free(B);\n",
    "    free(C_cpu);\n",
    "    free(C_gpu);\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77765e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : Support for offline compilation for architectures prior to '<compute/sm/lto>_75' will be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Vector Size: 5000000\n",
      "CPU Time: 21.823000 ms\n",
      "GPU Time: 0.375232 ms\n"
     ]
    }
   ],
   "source": [
    "!nvcc vector_addition.cu -o vector_addition\n",
    "!./vector_addition 5000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56e009b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting vector_sum_max_min.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile vector_sum_max_min.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cuda.h>\n",
    "#include <limits.h>\n",
    "#include <time.h>\n",
    "\n",
    "__global__ void reduceGPU(int *A, int *sum, int *max, int *min, int n)\n",
    "{\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (idx < n)\n",
    "    {\n",
    "        atomicAdd(sum, A[idx]);\n",
    "        atomicMax(max, A[idx]);\n",
    "        atomicMin(min, A[idx]);\n",
    "    }\n",
    "}\n",
    "\n",
    "void reduceCPU(int *A, int n, int *sum, int *max, int *min)\n",
    "{\n",
    "    *sum = 0;\n",
    "    *max = INT_MIN;\n",
    "    *min = INT_MAX;\n",
    "\n",
    "    for (int i = 0; i < n; i++)\n",
    "    {\n",
    "        *sum += A[i];\n",
    "        if (A[i] > *max) *max = A[i];\n",
    "        if (A[i] < *min) *min = A[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[])\n",
    "{\n",
    "    if (argc != 2)\n",
    "    {\n",
    "        printf(\"Usage: ./vector_sum_max_min <vector_size>\\n\");\n",
    "        return 0;\n",
    "    }\n",
    "\n",
    "    int n = atoi(argv[1]);\n",
    "    int size = n * sizeof(int);\n",
    "\n",
    "    int *A = (int *)malloc(size);\n",
    "    for (int i = 0; i < n; i++)\n",
    "        A[i] = rand() % 100;\n",
    "\n",
    "    int cpu_sum, cpu_max, cpu_min;\n",
    "\n",
    "    clock_t start_cpu = clock();\n",
    "    reduceCPU(A, n, &cpu_sum, &cpu_max, &cpu_min);\n",
    "    clock_t end_cpu = clock();\n",
    "\n",
    "    int *d_A, *d_sum, *d_max, *d_min;\n",
    "    cudaMalloc(&d_A, size);\n",
    "    cudaMalloc(&d_sum, sizeof(int));\n",
    "    cudaMalloc(&d_max, sizeof(int));\n",
    "    cudaMalloc(&d_min, sizeof(int));\n",
    "\n",
    "    cudaMemcpy(d_A, A, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    int zero = 0, min_init = INT_MAX, max_init = INT_MIN;\n",
    "    cudaMemcpy(d_sum, &zero, sizeof(int), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_max, &max_init, sizeof(int), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_min, &min_init, sizeof(int), cudaMemcpyHostToDevice);\n",
    "\n",
    "    cudaEvent_t start_gpu, stop_gpu;\n",
    "    cudaEventCreate(&start_gpu);\n",
    "    cudaEventCreate(&stop_gpu);\n",
    "\n",
    "    int threads = 256;\n",
    "    int blocks = (n + threads - 1) / threads;\n",
    "\n",
    "    cudaEventRecord(start_gpu);\n",
    "    reduceGPU<<<blocks, threads>>>(d_A, d_sum, d_max, d_min, n);\n",
    "    cudaEventRecord(stop_gpu);\n",
    "    cudaEventSynchronize(stop_gpu);\n",
    "\n",
    "    int gpu_sum, gpu_max, gpu_min;\n",
    "    cudaMemcpy(&gpu_sum, d_sum, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "    cudaMemcpy(&gpu_max, d_max, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "    cudaMemcpy(&gpu_min, d_min, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    float gpu_time;\n",
    "    cudaEventElapsedTime(&gpu_time, start_gpu, stop_gpu);\n",
    "\n",
    "    printf(\"Vector Size: %d\\n\", n);\n",
    "    printf(\"CPU -> Sum=%d Max=%d Min=%d\\n\", cpu_sum, cpu_max, cpu_min);\n",
    "    printf(\"CPU Time: %f ms\\n\",\n",
    "           (double)(end_cpu - start_cpu) * 1000 / CLOCKS_PER_SEC);\n",
    "\n",
    "    printf(\"GPU -> Sum=%d Max=%d Min=%d\\n\", gpu_sum, gpu_max, gpu_min);\n",
    "    printf(\"GPU Time: %f ms\\n\", gpu_time);\n",
    "\n",
    "    cudaFree(d_A);\n",
    "    cudaFree(d_sum);\n",
    "    cudaFree(d_max);\n",
    "    cudaFree(d_min);\n",
    "    free(A);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e28577d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : Support for offline compilation for architectures prior to '<compute/sm/lto>_75' will be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "Vector Size: 1000000\n",
      "CPU -> Sum=49498583 Max=99 Min=0\n",
      "CPU Time: 3.547000 ms\n",
      "GPU -> Sum=49498583 Max=99 Min=0\n",
      "GPU Time: 0.253984 ms\n"
     ]
    }
   ],
   "source": [
    "!nvcc vector_sum_max_min.cu -o vector_sum_max_min\n",
    "!./vector_sum_max_min 1000000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
