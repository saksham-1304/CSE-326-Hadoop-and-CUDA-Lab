{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e22e136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Feb 20 10:16:57 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   44C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59f22000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting matrix_mul_basic.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile matrix_mul_basic.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cuda.h>\n",
    "#include <time.h>\n",
    "\n",
    "#define TILE 16\n",
    "\n",
    "// CPU Multiplication\n",
    "void cpuMatMul(float *A, float *B, float *C, int N) {\n",
    "    for (int i = 0; i < N; i++)\n",
    "        for (int j = 0; j < N; j++) {\n",
    "            C[i*N + j] = 0;\n",
    "            for (int k = 0; k < N; k++)\n",
    "                C[i*N + j] += A[i*N + k] * B[k*N + j];\n",
    "        }\n",
    "}\n",
    "\n",
    "// GPU Kernel (No Shared Memory)\n",
    "__global__ void gpuMatMul(float *A, float *B, float *C, int N) {\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (row < N && col < N) {\n",
    "        float sum = 0;\n",
    "        for (int k = 0; k < N; k++)\n",
    "            sum += A[row*N + k] * B[k*N + col];\n",
    "        C[row*N + col] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]) {\n",
    "\n",
    "    if (argc != 2) {\n",
    "        printf(\"Usage: ./matrix_mul_basic <matrix_size>\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "    int N = atoi(argv[1]);\n",
    "    size_t size = N * N * sizeof(float);\n",
    "\n",
    "    float *A = (float*)malloc(size);\n",
    "    float *B = (float*)malloc(size);\n",
    "    float *C_cpu = (float*)malloc(size);\n",
    "    float *C_gpu = (float*)malloc(size);\n",
    "\n",
    "    for (int i = 0; i < N*N; i++) {\n",
    "        A[i] = rand() % 10;\n",
    "        B[i] = rand() % 10;\n",
    "    }\n",
    "\n",
    "    // CPU Timing\n",
    "    clock_t start = clock();\n",
    "    cpuMatMul(A, B, C_cpu, N);\n",
    "    clock_t end = clock();\n",
    "    double cpu_time = (double)(end - start) / CLOCKS_PER_SEC;\n",
    "\n",
    "    float *d_A, *d_B, *d_C;\n",
    "    cudaMalloc(&d_A, size);\n",
    "    cudaMalloc(&d_B, size);\n",
    "    cudaMalloc(&d_C, size);\n",
    "\n",
    "    cudaMemcpy(d_A, A, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_B, B, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 threads(TILE, TILE);\n",
    "    dim3 blocks((N + TILE - 1)/TILE, (N + TILE - 1)/TILE);\n",
    "\n",
    "    cudaEvent_t gstart, gend;\n",
    "    cudaEventCreate(&gstart);\n",
    "    cudaEventCreate(&gend);\n",
    "\n",
    "    cudaEventRecord(gstart);\n",
    "    gpuMatMul<<<blocks, threads>>>(d_A, d_B, d_C, N);\n",
    "    cudaEventRecord(gend);\n",
    "    cudaEventSynchronize(gend);\n",
    "\n",
    "    float gpu_time;\n",
    "    cudaEventElapsedTime(&gpu_time, gstart, gend);\n",
    "\n",
    "    printf(\"\\nMatrix Size: %d x %d\\n\", N, N);\n",
    "    printf(\"CPU Time: %f seconds\\n\", cpu_time);\n",
    "    printf(\"GPU Time: %f ms\\n\", gpu_time);\n",
    "\n",
    "    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n",
    "    free(A); free(B); free(C_cpu); free(C_gpu);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2989d5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : Support for offline compilation for architectures prior to '<compute/sm/lto>_75' will be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "\n",
      "Matrix Size: 512 x 512\n",
      "CPU Time: 1.119478 seconds\n",
      "GPU Time: 102.656548 ms\n"
     ]
    }
   ],
   "source": [
    "!nvcc matrix_mul_basic.cu -o matrix_mul_basic\n",
    "!./matrix_mul_basic 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f366d95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing matrix_mul_shared.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile matrix_mul_shared.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cuda.h>\n",
    "#include <time.h>\n",
    "\n",
    "#define TILE 16\n",
    "\n",
    "void cpuMatMul(float *A, float *B, float *C, int N) {\n",
    "    for (int i = 0; i < N; i++)\n",
    "        for (int j = 0; j < N; j++) {\n",
    "            C[i*N + j] = 0;\n",
    "            for (int k = 0; k < N; k++)\n",
    "                C[i*N + j] += A[i*N + k] * B[k*N + j];\n",
    "        }\n",
    "}\n",
    "\n",
    "__global__ void gpuMatMulShared(float *A, float *B, float *C, int N) {\n",
    "\n",
    "    __shared__ float sA[TILE][TILE];\n",
    "    __shared__ float sB[TILE][TILE];\n",
    "\n",
    "    int row = blockIdx.y * TILE + threadIdx.y;\n",
    "    int col = blockIdx.x * TILE + threadIdx.x;\n",
    "\n",
    "    float sum = 0;\n",
    "\n",
    "    for (int t = 0; t < (N + TILE - 1)/TILE; t++) {\n",
    "\n",
    "        if (row < N && t*TILE + threadIdx.x < N)\n",
    "            sA[threadIdx.y][threadIdx.x] = A[row*N + t*TILE + threadIdx.x];\n",
    "        else\n",
    "            sA[threadIdx.y][threadIdx.x] = 0;\n",
    "\n",
    "        if (col < N && t*TILE + threadIdx.y < N)\n",
    "            sB[threadIdx.y][threadIdx.x] = B[(t*TILE + threadIdx.y)*N + col];\n",
    "        else\n",
    "            sB[threadIdx.y][threadIdx.x] = 0;\n",
    "\n",
    "        __syncthreads();\n",
    "\n",
    "        for (int k = 0; k < TILE; k++)\n",
    "            sum += sA[threadIdx.y][k] * sB[k][threadIdx.x];\n",
    "\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    if (row < N && col < N)\n",
    "        C[row*N + col] = sum;\n",
    "}\n",
    "\n",
    "int main(int argc, char *argv[]) {\n",
    "\n",
    "    if (argc != 2) {\n",
    "        printf(\"Usage: ./matrix_mul_shared <matrix_size>\\n\");\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "    int N = atoi(argv[1]);\n",
    "    size_t size = N * N * sizeof(float);\n",
    "\n",
    "    float *A = (float*)malloc(size);\n",
    "    float *B = (float*)malloc(size);\n",
    "    float *C_cpu = (float*)malloc(size);\n",
    "    float *C_gpu = (float*)malloc(size);\n",
    "\n",
    "    for (int i = 0; i < N*N; i++) {\n",
    "        A[i] = rand() % 10;\n",
    "        B[i] = rand() % 10;\n",
    "    }\n",
    "\n",
    "    clock_t start = clock();\n",
    "    cpuMatMul(A, B, C_cpu, N);\n",
    "    clock_t end = clock();\n",
    "    double cpu_time = (double)(end - start) / CLOCKS_PER_SEC;\n",
    "\n",
    "    float *d_A, *d_B, *d_C;\n",
    "    cudaMalloc(&d_A, size);\n",
    "    cudaMalloc(&d_B, size);\n",
    "    cudaMalloc(&d_C, size);\n",
    "\n",
    "    cudaMemcpy(d_A, A, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_B, B, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 threads(TILE, TILE);\n",
    "    dim3 blocks((N + TILE - 1)/TILE, (N + TILE - 1)/TILE);\n",
    "\n",
    "    cudaEvent_t gstart, gend;\n",
    "    cudaEventCreate(&gstart);\n",
    "    cudaEventCreate(&gend);\n",
    "\n",
    "    cudaEventRecord(gstart);\n",
    "    gpuMatMulShared<<<blocks, threads>>>(d_A, d_B, d_C, N);\n",
    "    cudaEventRecord(gend);\n",
    "    cudaEventSynchronize(gend);\n",
    "\n",
    "    float gpu_time;\n",
    "    cudaEventElapsedTime(&gpu_time, gstart, gend);\n",
    "\n",
    "    printf(\"\\nMatrix Size: %d x %d\\n\", N, N);\n",
    "    printf(\"CPU Time: %f seconds\\n\", cpu_time);\n",
    "    printf(\"GPU Time (Shared Memory): %f ms\\n\", gpu_time);\n",
    "\n",
    "    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n",
    "    free(A); free(B); free(C_cpu); free(C_gpu);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdca4df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc warning : Support for offline compilation for architectures prior to '<compute/sm/lto>_75' will be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
      "\n",
      "Matrix Size: 512 x 512\n",
      "CPU Time: 1.162507 seconds\n",
      "GPU Time (Shared Memory): 0.746944 ms\n"
     ]
    }
   ],
   "source": [
    "!nvcc matrix_mul_shared.cu -o matrix_mul_shared\n",
    "!./matrix_mul_shared 512"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
