{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "406b3e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Feb  6 09:25:43 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   52C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b2db806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting matrix_add.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile matrix_add.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda.h>\n",
    "\n",
    "// Macro for error checking\n",
    "#define cudaCheckError() {                                          \\\n",
    " cudaError_t e=cudaGetLastError();                                 \\\n",
    " if(e!=cudaSuccess) {                                              \\\n",
    "   printf(\"Cuda failure %s:%d: '%s'\\n\",__FILE__,__LINE__,cudaGetErrorString(e)); \\\n",
    "   return 1;                                                       \\\n",
    " }                                                                 \\\n",
    "}\n",
    "\n",
    "__global__ void matrixAdd(int *a, int *b, int *c, int n) {\n",
    "    int id = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    if (id < n) {\n",
    "        c[id] = a[id] + b[id];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int rows, cols;\n",
    "\n",
    "    // 1. Get Matrix Size\n",
    "    if(scanf(\"%d\", &rows) != 1) { printf(\"Error reading rows\\n\"); return 1; }\n",
    "    if(scanf(\"%d\", &cols) != 1) { printf(\"Error reading cols\\n\"); return 1; }\n",
    "\n",
    "    int n = rows * cols;\n",
    "    size_t bytes = n * sizeof(int);\n",
    "\n",
    "    // 2. Allocate Host Memory\n",
    "    int *h_a = (int*)malloc(bytes);\n",
    "    int *h_b = (int*)malloc(bytes);\n",
    "    int *h_c = (int*)malloc(bytes);\n",
    "\n",
    "    // 3. Read Input\n",
    "    for(int i = 0; i < n; i++) scanf(\"%d\", &h_a[i]);\n",
    "    for(int i = 0; i < n; i++) scanf(\"%d\", &h_b[i]);\n",
    "\n",
    "    // 4. Allocate Device Memory & Check for Errors\n",
    "    int *d_a, *d_b, *d_c;\n",
    "    cudaMalloc(&d_a, bytes);\n",
    "    cudaMalloc(&d_b, bytes);\n",
    "    cudaMalloc(&d_c, bytes);\n",
    "    cudaCheckError(); // Check if GPU allocation worked\n",
    "\n",
    "    // 5. Copy to Device\n",
    "    cudaMemcpy(d_a, h_a, bytes, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_b, h_b, bytes, cudaMemcpyHostToDevice);\n",
    "    cudaCheckError();\n",
    "\n",
    "    // 6. Launch Kernel\n",
    "    int blockSize = 256;\n",
    "    int gridSize = (n + blockSize - 1) / blockSize;\n",
    "    \n",
    "    // Print debug info\n",
    "    printf(\"Launching kernel (Grid: %d, Block: %d) on %d elements...\\n\", gridSize, blockSize, n);\n",
    "    \n",
    "    matrixAdd<<<gridSize, blockSize>>>(d_a, d_b, d_c, n);\n",
    "    cudaDeviceSynchronize(); // Wait for GPU to finish\n",
    "    cudaCheckError(); // Check if Kernel crashed\n",
    "\n",
    "    // 7. Copy back\n",
    "    cudaMemcpy(h_c, d_c, bytes, cudaMemcpyDeviceToHost);\n",
    "    cudaCheckError();\n",
    "\n",
    "    // 8. Print Result\n",
    "    printf(\"\\nResult Matrix C (Addition):\\n\");\n",
    "    for(int i = 0; i < rows; i++) {\n",
    "        for(int j = 0; j < cols; j++) {\n",
    "            printf(\"%d\\t\", h_c[i * cols + j]);\n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "\n",
    "    // Free memory\n",
    "    cudaFree(d_a); cudaFree(d_b); cudaFree(d_c);\n",
    "    free(h_a); free(h_b); free(h_c);\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2820e8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching kernel (Grid: 1, Block: 256) on 4 elements...\n",
      "\n",
      "Result Matrix C (Addition):\n",
      "6\t8\t\n",
      "10\t12\t\n"
     ]
    }
   ],
   "source": [
    "!nvcc -arch=sm_75 matrix_add.cu -o matrix_add\n",
    "!echo \"2 2 1 2 3 4 5 6 7 8\" | ./matrix_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5f76329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing matrix_mul.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile matrix_mul.cu\n",
    "#include <stdio.h>\n",
    "#include <cuda.h>\n",
    "\n",
    "// Macro for error checking\n",
    "#define cudaCheckError() {                                          \\\n",
    " cudaError_t e=cudaGetLastError();                                 \\\n",
    " if(e!=cudaSuccess) {                                              \\\n",
    "   printf(\"Cuda failure %s:%d: '%s'\\n\",__FILE__,__LINE__,cudaGetErrorString(e)); \\\n",
    "   return 1;                                                       \\\n",
    " }                                                                 \\\n",
    "}\n",
    "\n",
    "// CUDA Kernel for Matrix Multiplication\n",
    "__global__ void matrixMul(int *a, int *b, int *c, int rowsA, int colsA, int colsB) {\n",
    "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (row < rowsA && col < colsB) {\n",
    "        int sum = 0;\n",
    "        for (int k = 0; k < colsA; k++) {\n",
    "            sum += a[row * colsA + k] * b[k * colsB + col];\n",
    "        }\n",
    "        c[row * colsB + col] = sum;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int r1, c1, r2, c2;\n",
    "\n",
    "    printf(\"--- Matrix Multiplication ---\\n\");\n",
    "\n",
    "    // 1. Input Dimensions\n",
    "    printf(\"Matrix A - Enter rows and columns: \");\n",
    "    if(scanf(\"%d %d\", &r1, &c1) != 2) return 1;\n",
    "\n",
    "    printf(\"Matrix B - Enter rows and columns: \");\n",
    "    if(scanf(\"%d %d\", &r2, &c2) != 2) return 1;\n",
    "\n",
    "    // 2. Check compatibility\n",
    "    if (c1 != r2) {\n",
    "        printf(\"Error: Columns of A (%d) must match Rows of B (%d)\\n\", c1, r2);\n",
    "        return -1;\n",
    "    }\n",
    "\n",
    "    size_t bytes_a = r1 * c1 * sizeof(int);\n",
    "    size_t bytes_b = r2 * c2 * sizeof(int);\n",
    "    size_t bytes_c = r1 * c2 * sizeof(int);\n",
    "\n",
    "    // 3. Allocate Host Memory\n",
    "    int *h_a = (int*)malloc(bytes_a);\n",
    "    int *h_b = (int*)malloc(bytes_b);\n",
    "    int *h_c = (int*)malloc(bytes_c);\n",
    "\n",
    "    // 4. Input Elements\n",
    "    printf(\"\\nEnter Matrix A elements (%d x %d):\\n\", r1, c1);\n",
    "    for (int i = 0; i < r1 * c1; i++) scanf(\"%d\", &h_a[i]);\n",
    "\n",
    "    printf(\"\\nEnter Matrix B elements (%d x %d):\\n\", r2, c2);\n",
    "    for (int i = 0; i < r2 * c2; i++) scanf(\"%d\", &h_b[i]);\n",
    "\n",
    "    // 5. Allocate Device Memory\n",
    "    int *d_a, *d_b, *d_c;\n",
    "    cudaMalloc(&d_a, bytes_a);\n",
    "    cudaMalloc(&d_b, bytes_b);\n",
    "    cudaMalloc(&d_c, bytes_c);\n",
    "    cudaCheckError();\n",
    "\n",
    "    // 6. Copy Host to Device\n",
    "    cudaMemcpy(d_a, h_a, bytes_a, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_b, h_b, bytes_b, cudaMemcpyHostToDevice);\n",
    "    cudaCheckError();\n",
    "\n",
    "    // 7. Define Grid and Block Dimensions\n",
    "    dim3 threadsPerBlock(16, 16);\n",
    "    dim3 blocksPerGrid((c2 + threadsPerBlock.x - 1) / threadsPerBlock.x,\n",
    "                       (r1 + threadsPerBlock.y - 1) / threadsPerBlock.y);\n",
    "\n",
    "    printf(\"\\nLaunching kernel with Grid(%d, %d)...\\n\", blocksPerGrid.x, blocksPerGrid.y);\n",
    "    \n",
    "    // Launch Kernel\n",
    "    matrixMul<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c, r1, c1, c2);\n",
    "    cudaDeviceSynchronize(); // Wait for GPU\n",
    "    cudaCheckError();        // Check for kernel errors\n",
    "\n",
    "    // 8. Copy Result to Host\n",
    "    cudaMemcpy(h_c, d_c, bytes_c, cudaMemcpyDeviceToHost);\n",
    "    cudaCheckError();\n",
    "\n",
    "    // 9. Display Result\n",
    "    printf(\"\\nResult Matrix C (Multiplication):\\n\");\n",
    "    for (int i = 0; i < r1; i++) {\n",
    "        for (int j = 0; j < c2; j++) {\n",
    "            printf(\"%d\\t\", h_c[i * c2 + j]);\n",
    "        }\n",
    "        printf(\"\\n\");\n",
    "    }\n",
    "\n",
    "    // 10. Free Memory\n",
    "    cudaFree(d_a); cudaFree(d_b); cudaFree(d_c);\n",
    "    free(h_a); free(h_b); free(h_c);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39256f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Matrix Multiplication ---\n",
      "Matrix A - Enter rows and columns: Matrix B - Enter rows and columns: \n",
      "Enter Matrix A elements (2 x 2):\n",
      "\n",
      "Enter Matrix B elements (2 x 2):\n",
      "\n",
      "Launching kernel with Grid(1, 1)...\n",
      "\n",
      "Result Matrix C (Multiplication):\n",
      "4\t4\t\n",
      "10\t8\t\n"
     ]
    }
   ],
   "source": [
    "!nvcc -arch=sm_75 matrix_mul.cu -o matrix_mul\n",
    "!echo \"2 2 2 2 1 2 3 4 2 0 1 2\" | ./matrix_mul"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
